{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed18e9f-11f7-42b1-9878-23df8d648949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2026-01-25 15:18:06,530:jax._src.xla_bridge:834: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "15:18:06: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from confignb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f746ecc5-3ddd-402a-a656-b6ebce8a0ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, pts, ks = h.load_data(DATA_DIR / 'ASCADv_clean.h5')\n",
    "best_feats_idx = np.load('data/rf_rfe_5_best.npy')\n",
    "X = X.rename(columns=str)\n",
    "X_best = X.iloc[:, best_feats_idx[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87856976-8a39-46eb-9c39-025a2e75cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fft\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "def _feat_window(X, f, n, k):\n",
    "    i = list(n).index(f)\n",
    "    return X[:, i-k:i+k]\n",
    "\n",
    "@h.dataclass\n",
    "class FFTFeaturizer(TransformerMixin):\n",
    "    feats: list\n",
    "    names: list\n",
    "    k: int = 8\n",
    "    n: int = 8\n",
    "\n",
    "    def _fft_feat(self, W):\n",
    "        freqs = fft.rfft(W, axis=1)\n",
    "        return np.abs(freqs)[:, 1:self.n+1]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        windows = [_feat_window(X, f, self.names, self.k)\n",
    "                   for f in self.feats]\n",
    "        return np.concat([self._fft_feat(W) for W in windows], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cfdfe91-c787-404f-a5f5-0ffb635d43e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notuser/workspace/SCA/.venv/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:993: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "15:20:40: [1] Mean PI: -inf\n",
      "/home/notuser/workspace/SCA/.venv/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:993: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "15:20:45: [2] Mean PI: -inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m rf = m.SimpleRFC(max_depth=\u001b[32m10\u001b[39m)\n\u001b[32m      8\u001b[39m pl_rf = m.make_pipeline(feats, rf)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_best\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/SCA/sca/helpers.py:107\u001b[39m, in \u001b[36mcv\u001b[39m\u001b[34m(seed, model, X, y, pts, ks, n_repeats, n_splits, verbose, skip_last)\u001b[39m\n\u001b[32m    103\u001b[39m X_atk, pts_atk, ks_atk = X.iloc[atk_idx], pts.iloc[atk_idx], ks.iloc[atk_idx]\n\u001b[32m    105\u001b[39m model.fit(X_prof, y_prof)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m log_proba = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_log_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_atk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m log_proba = jnp.array(log_proba) / jnp.log(\u001b[32m2.0\u001b[39m)\n\u001b[32m    109\u001b[39m scores = compute_pi(log_proba, pts_atk.values[:, \u001b[32m2\u001b[39m], ks_atk.values[:, \u001b[32m2\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/SCA/.venv/lib/python3.13/site-packages/sklearn/pipeline.py:987\u001b[39m, in \u001b[36mPipeline.predict_log_proba\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    985\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    986\u001b[39m         Xt = transform.transform(Xt)\n\u001b[32m--> \u001b[39m\u001b[32m987\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_log_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[32m    990\u001b[39m routed_params = process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict_log_proba\u001b[39m\u001b[33m\"\u001b[39m, **params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/SCA/.venv/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:990\u001b[39m, in \u001b[36mForestClassifier.predict_log_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    969\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_log_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    970\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[33;03m    Predict class log-probabilities for X.\u001b[39;00m\n\u001b[32m    972\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    988\u001b[39m \u001b[33;03m        classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m990\u001b[39m     proba = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    992\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m:\n\u001b[32m    993\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.log(proba)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/SCA/.venv/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:956\u001b[39m, in \u001b[36mForestClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    951\u001b[39m all_proba = [\n\u001b[32m    952\u001b[39m     np.zeros((X.shape[\u001b[32m0\u001b[39m], j), dtype=np.float64)\n\u001b[32m    953\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np.atleast_1d(\u001b[38;5;28mself\u001b[39m.n_classes_)\n\u001b[32m    954\u001b[39m ]\n\u001b[32m    955\u001b[39m lock = threading.Lock()\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msharedmem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimators_\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[32m    962\u001b[39m     proba /= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/SCA/.venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/SCA/.venv/lib/python3.13/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/SCA/.venv/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/SCA/.venv/lib/python3.13/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion([\n",
    "    (\"fft\", FFTFeaturizer([\"187\", \"1070\"], X_best.columns, k=4, n=1)),\n",
    "])\n",
    "rf = m.SimpleRFC(max_depth=10)\n",
    "pl_rf = m.make_pipeline(feats, rf)\n",
    "\n",
    "h.cv(SEED, pl_rf, X_best, y, pts, ks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
